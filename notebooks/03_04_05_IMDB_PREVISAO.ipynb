{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcba9f2d",
   "metadata": {},
   "source": [
    "# 3. Previsão da nota do IMDb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1f18ee",
   "metadata": {},
   "source": [
    "## 3.0 Imports: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "015b1cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:20: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:20: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\guima\\AppData\\Local\\Temp\\ipykernel_3740\\228565998.py:20: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  df = pd.read_csv('..\\data\\processed\\df_eda01_plus_5000.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from pathlib import Path\n",
    "import joblib, sklearn, sys\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('..\\data\\processed\\df_eda01_plus_5000.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edb45b5",
   "metadata": {},
   "source": [
    "## 3.1 Definição do problema\n",
    "O objetivo é prever a nota do IMDb (**IMDB_Rating**) a partir das demais variáveis disponíveis.  \n",
    "\n",
    "- Como a variável alvo é **contínua (0–10)**, trata-se de um **problema de regressão**.  \n",
    "- Opcionalmente, poderíamos transformar a nota em faixas (ruim/médio/bom/excelente), mas isso implicaria em um **problema de classificação ordinal**, com perda de informação.  \n",
    "\n",
    "### Modelos de Regressão considerados\n",
    "Para esse tipo de tarefa, alguns modelos de regressão supervisionada podem ser aplicados:\n",
    "\n",
    "- **Regressão Linear**  \n",
    "  Simples e interpretável, útil como baseline. Porém, pode não capturar relações não lineares entre as variáveis.  \n",
    "\n",
    "- **Árvore de Decisão / Random Forest Regressor**  \n",
    "  Captura relações mais complexas, lida bem com variáveis categóricas (via encoding) e não exige normalização. Bom para dados tabulares.  \n",
    "\n",
    "- **Gradient Boosting (XGBoost, LightGBM, HistGradientBoosting)**  \n",
    "  Combina várias árvores de forma sequencial para reduzir o erro residual. Em geral apresenta excelente performance em dados tabulares.  \n",
    "  *Observação:* **HistGradientBoosting** é a implementação nativa do scikit-learn, otimizada por histogramas (rápida e integrada ao ecossistema sklearn).\n",
    "\n",
    "- **CatBoost**  \n",
    "  Método de boosting que trata variáveis categóricas de forma mais eficiente (estatísticas ordenadas), costuma ser muito competitivo com pouco *tuning* e bom controle de *overfitting*. Em geral entrega resultados robustos em dados tabulares.\n",
    "\n",
    "> Dessa forma, começamos com um modelo **simples (Regressão Linear)** para servir de *baseline* e, em seguida, testamos modelos baseados em árvores e boosting (**Random Forest, HistGradientBoosting, XGBoost e CatBoost**) para verificar ganhos de performance (métricas: **RMSE** principal, além de **MAE** e **R²**).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7860a0",
   "metadata": {},
   "source": [
    "## 3.2 Seleção e tratamento de variáveis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66987513",
   "metadata": {},
   "source": [
    "### 3.2.1 Tratamento de valores nulos\n",
    "Antes de selecionar as variáveis preditoras para o modelo, é importante tratar os **valores ausentes** no dataset.  \n",
    "Valores nulos podem distorcer estatísticas, atrapalhar transformações (como normalização) e prejudicar o desempenho dos modelos de Machine Learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "df1e8065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series_Title        0\n",
       "Released_Year       1\n",
       "Certificate       316\n",
       "IMDB_Rating         0\n",
       "Overview          123\n",
       "Meta_score       4420\n",
       "Director            0\n",
       "Star1               0\n",
       "Star2               1\n",
       "Star3               4\n",
       "No_of_Votes         0\n",
       "Genres_list         0\n",
       "Action              0\n",
       "Adventure           0\n",
       "Animation           0\n",
       "Biography           0\n",
       "Comedy              0\n",
       "Crime               0\n",
       "Drama               0\n",
       "Family              0\n",
       "Fantasy             0\n",
       "Film-Noir           0\n",
       "History             0\n",
       "Horror              0\n",
       "Music               0\n",
       "Musical             0\n",
       "Mystery             0\n",
       "Romance             0\n",
       "Sci-Fi              0\n",
       "Sport               0\n",
       "Thriller            0\n",
       "War                 0\n",
       "Western             0\n",
       "Runtime            12\n",
       "Gross             849\n",
       "budget            932\n",
       "dtype: int64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6aa739f",
   "metadata": {},
   "source": [
    "Foram aplicados os seguintes tratamentos:\n",
    "\n",
    "- `Certificate`: valores nulos preenchidos com \"R\".  \n",
    "- `Released_Year`, `Star2`, `Star3`, `Runtime`: registros com valores nulos removidos.  \n",
    "- `Overview`: registros com valores nulos removidos.  \n",
    "- `Gross`: valores nulos preenchidos com a mediana da coluna.  \n",
    "- `budget`: valores nulos preenchidos com a mediana da coluna.  \n",
    "- Índice do DataFrame redefinido após as remoções.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "9d7eafe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Novo shape do df: (5246, 36)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guima\\AppData\\Local\\Temp\\ipykernel_3740\\2255263276.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Certificate'].fillna(\"R\", inplace= True)\n",
      "C:\\Users\\guima\\AppData\\Local\\Temp\\ipykernel_3740\\2255263276.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"Gross\"].fillna(df[\"Gross\"].median(), inplace=True)\n",
      "C:\\Users\\guima\\AppData\\Local\\Temp\\ipykernel_3740\\2255263276.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"budget\"].fillna(df[\"budget\"].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df['Certificate'].fillna(\"R\", inplace= True)\n",
    "df.dropna(subset=[\"Released_Year\", \"Star2\", \"Star3\", \"Runtime\"], inplace=True)\n",
    "print(\"Novo shape do df:\", df.shape)\n",
    "df.dropna(subset=[\"Overview\"], inplace=True)\n",
    "df[\"Gross\"].fillna(df[\"Gross\"].median(), inplace=True)\n",
    "df[\"budget\"].fillna(df[\"budget\"].median(), inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "3167f05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"Series_Title\"] != \"The Shawshank Redemption\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0cd7ea",
   "metadata": {},
   "source": [
    "### 3.2.2 Seleção de variáveis\n",
    "\n",
    "As variáveis preditoras selecionadas foram:\n",
    "\n",
    "- `Released_Year`: o ano de lançamento pode influenciar a recepção e, consequentemente, a nota.  \n",
    "- `Certificate`: a classificação indicativa pode afetar o público-alvo e o tipo de conteúdo.  \n",
    "- `Director`, `Star1`, `Star2`, `Star3`: equipe criativa e atores principais exercem grande impacto na percepção de qualidade.  \n",
    "- `No_of_Votes`: representa a popularidade do filme e tende a ter forte correlação com a nota.  \n",
    "- `Genres_list` e colunas dummies de gênero (`Action`, `Adventure`, ..., `Western`): o gênero influencia o perfil do público e a forma como o filme é avaliado.  \n",
    "- `Runtime`: a duração pode estar relacionada à recepção do público.  \n",
    "- `Gross` e `budget`: orçamento e bilheteria refletem aspectos financeiros que podem se relacionar com a qualidade percebida.\n",
    "\n",
    "A variável alvo (target) é:\n",
    "\n",
    "- `IMDB_Rating`\n",
    "\n",
    "Variáveis não utilizadas:\n",
    "\n",
    "- `Series_Title`: apenas identifica o filme, não possui valor preditivo.  \n",
    "- `Overview`: exige processamento de linguagem natural (NLP) para ser usada de forma adequada, o que está fora do escopo nesta análise.  \n",
    "- `Meta_score`: apresenta muitos valores ausentes, dificultando seu uso como variável preditora.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b03f6e",
   "metadata": {},
   "source": [
    "### 3.2.3 Transformações aplicadas\n",
    "\n",
    "Para preparar as variáveis selecionadas, foram adotadas as seguintes transformações:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b295ee5",
   "metadata": {},
   "source": [
    "#### 3.2.3.1 Tratamento das variáveis numéricas\n",
    "\n",
    "Foram consideradas numéricas as colunas:\n",
    "- `Released_Year`, `Runtime`  \n",
    "- `Gross`, `budget`, `No_of_Votes`\n",
    "\n",
    "Tratamentos aplicados:\n",
    "\n",
    "- **Padronização (StandardScaler)** em todas as variáveis numéricas, para colocar na mesma escala (média 0 e desvio padrão 1).\n",
    "- **Transformação logarítmica (log1p)** previamente em variáveis altamente enviesadas:\n",
    "  - `Gross`, `budget`, `No_of_Votes`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "0fe49e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape após pré-processamento numérico: (5129, 5)\n"
     ]
    }
   ],
   "source": [
    "# Definição das colunas numéricas\n",
    "num_linear = [\"Released_Year\", \"Runtime\"]\n",
    "num_skewed = [\"Gross\", \"budget\", \"No_of_Votes\"]\n",
    "\n",
    "# Pipelines numéricos\n",
    "numeric_linear_pipe = Pipeline(steps=[\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "numeric_skewed_pipe = Pipeline(steps=[\n",
    "    (\"log1p\", FunctionTransformer(np.log1p, validate=False)),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "# ColumnTransformer apenas para as numéricas\n",
    "num_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num_linear\", numeric_linear_pipe, num_linear),\n",
    "        (\"num_skewed\", numeric_skewed_pipe, num_skewed),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "# Exemplo de uso\n",
    "X_num = df[num_linear + num_skewed].copy()\n",
    "X_num_proc = num_preprocessor.fit_transform(X_num)\n",
    "\n",
    "print(\"Shape após pré-processamento numérico:\", X_num_proc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "fa80043e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>std_Released_Year</th>\n",
       "      <th>std_Runtime</th>\n",
       "      <th>log1p_std_Gross</th>\n",
       "      <th>log1p_std_budget</th>\n",
       "      <th>log1p_std_No_of_Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.854601</td>\n",
       "      <td>2.864626</td>\n",
       "      <td>1.075159</td>\n",
       "      <td>-0.676131</td>\n",
       "      <td>2.209229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.488205</td>\n",
       "      <td>1.853034</td>\n",
       "      <td>1.723030</td>\n",
       "      <td>1.674331</td>\n",
       "      <td>2.410428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.724445</td>\n",
       "      <td>4.052147</td>\n",
       "      <td>0.672068</td>\n",
       "      <td>-0.146074</td>\n",
       "      <td>2.002986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.830770</td>\n",
       "      <td>-0.609972</td>\n",
       "      <td>-0.539866</td>\n",
       "      <td>-2.624165</td>\n",
       "      <td>1.720658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.162815</td>\n",
       "      <td>4.008165</td>\n",
       "      <td>1.559523</td>\n",
       "      <td>1.210174</td>\n",
       "      <td>2.217081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   std_Released_Year  std_Runtime  log1p_std_Gross  log1p_std_budget  \\\n",
       "0          -1.854601     2.864626         1.075159         -0.676131   \n",
       "1           0.488205     1.853034         1.723030          1.674331   \n",
       "2          -1.724445     4.052147         0.672068         -0.146074   \n",
       "3          -2.830770    -0.609972        -0.539866         -2.624165   \n",
       "4           0.162815     4.008165         1.559523          1.210174   \n",
       "\n",
       "   log1p_std_No_of_Votes  \n",
       "0               2.209229  \n",
       "1               2.410428  \n",
       "2               2.002986  \n",
       "3               1.720658  \n",
       "4               2.217081  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = (\n",
    "    [f\"std_{c}\" for c in num_linear] +\n",
    "    [f\"log1p_std_{c}\" for c in num_skewed]\n",
    ")\n",
    "\n",
    "X_num_proc_df = pd.DataFrame(\n",
    "    X_num_proc, columns=feature_names, index=X_num.index\n",
    ")\n",
    "X_num_proc_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110dac2a",
   "metadata": {},
   "source": [
    "Resumo:\n",
    "- `Released_Year`, `Runtime` → `StandardScaler`  \n",
    "- `Gross`, `budget`, `No_of_Votes` → `log1p` → `StandardScaler`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03937449",
   "metadata": {},
   "source": [
    "#### 3.2.3.2 Transformações das variáveis categóricas\n",
    "\n",
    "Variáveis categóricas consideradas:\n",
    "- `Certificate`, `Director`, `Star1`, `Star2`, `Star3`\n",
    "\n",
    "Transformações aplicadas:\n",
    "- `Certificate` → **One-Hot Encoding** (baixa cardinalidade), com `handle_unknown=\"ignore\"`.\n",
    "- `Director`, `Star1`, `Star2`, `Star3` → **Frequency Encoding** (alta cardinalidade), codificando cada categoria pela sua frequência relativa no conjunto de treino para evitar explosão de dimensionalidade.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "58637d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape após pré-processamento categórico: (5129, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Certificate_16</th>\n",
       "      <th>Certificate_A</th>\n",
       "      <th>Certificate_Approved</th>\n",
       "      <th>Certificate_G</th>\n",
       "      <th>Certificate_GP</th>\n",
       "      <th>Certificate_M</th>\n",
       "      <th>Certificate_NC-17</th>\n",
       "      <th>Certificate_Not Rated</th>\n",
       "      <th>Certificate_PG</th>\n",
       "      <th>Certificate_PG-13</th>\n",
       "      <th>...</th>\n",
       "      <th>Certificate_TV-PG</th>\n",
       "      <th>Certificate_U</th>\n",
       "      <th>Certificate_U/A</th>\n",
       "      <th>Certificate_UA</th>\n",
       "      <th>Certificate_Unrated</th>\n",
       "      <th>Certificate_X</th>\n",
       "      <th>freq_Director</th>\n",
       "      <th>freq_Star1</th>\n",
       "      <th>freq_Star2</th>\n",
       "      <th>freq_Star3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>0.000195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001755</td>\n",
       "      <td>0.004484</td>\n",
       "      <td>0.000975</td>\n",
       "      <td>0.000195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>0.004094</td>\n",
       "      <td>0.001365</td>\n",
       "      <td>0.001170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001755</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>0.001755</td>\n",
       "      <td>0.000195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Certificate_16  Certificate_A  Certificate_Approved  Certificate_G  \\\n",
       "0             0.0            1.0                   0.0            0.0   \n",
       "1             0.0            0.0                   0.0            0.0   \n",
       "2             0.0            1.0                   0.0            0.0   \n",
       "3             0.0            0.0                   0.0            0.0   \n",
       "4             0.0            0.0                   0.0            0.0   \n",
       "\n",
       "   Certificate_GP  Certificate_M  Certificate_NC-17  Certificate_Not Rated  \\\n",
       "0             0.0            0.0                0.0                    0.0   \n",
       "1             0.0            0.0                0.0                    0.0   \n",
       "2             0.0            0.0                0.0                    0.0   \n",
       "3             0.0            0.0                0.0                    0.0   \n",
       "4             0.0            0.0                0.0                    0.0   \n",
       "\n",
       "   Certificate_PG  Certificate_PG-13  ...  Certificate_TV-PG  Certificate_U  \\\n",
       "0             0.0                0.0  ...                0.0            0.0   \n",
       "1             0.0                0.0  ...                0.0            0.0   \n",
       "2             0.0                0.0  ...                0.0            0.0   \n",
       "3             0.0                0.0  ...                0.0            1.0   \n",
       "4             0.0                0.0  ...                0.0            1.0   \n",
       "\n",
       "   Certificate_U/A  Certificate_UA  Certificate_Unrated  Certificate_X  \\\n",
       "0              0.0             0.0                  0.0            0.0   \n",
       "1              0.0             1.0                  0.0            0.0   \n",
       "2              0.0             0.0                  0.0            0.0   \n",
       "3              0.0             0.0                  0.0            0.0   \n",
       "4              0.0             0.0                  0.0            0.0   \n",
       "\n",
       "   freq_Director  freq_Star1  freq_Star2  freq_Star3  \n",
       "0       0.002145    0.000780    0.001170    0.000195  \n",
       "1       0.001755    0.004484    0.000975    0.000195  \n",
       "2       0.002145    0.004094    0.001365    0.001170  \n",
       "3       0.001560    0.000585    0.000195    0.000585  \n",
       "4       0.001755    0.000585    0.001755    0.000195  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cat_low  = [\"Certificate\"]                         # baixa cardinalidade\n",
    "cat_high = [\"Director\", \"Star1\", \"Star2\", \"Star3\"] # alta cardinalidade\n",
    "\n",
    "\n",
    "class FrequencyEncoder(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.maps_ = None\n",
    "        self.cols_ = None\n",
    "        self.n_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = pd.DataFrame(X)\n",
    "        self.cols_ = list(X.columns)\n",
    "        self.n_ = len(X)\n",
    "        self.maps_ = {}\n",
    "        for i, c in enumerate(self.cols_):\n",
    "            vc = X.iloc[:, i].astype(str).value_counts(dropna=False)\n",
    "            freq = (vc / self.n_).to_dict()\n",
    "            self.maps_[c] = freq\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = pd.DataFrame(X)\n",
    "        outs = []\n",
    "        for i, c in enumerate(self.cols_):\n",
    "            m = self.maps_[c]\n",
    "            col = (\n",
    "                X.iloc[:, i]\n",
    "                .astype(str)\n",
    "                .map(m)\n",
    "                .fillna(0.0)\n",
    "                .to_numpy()\n",
    "                .reshape(-1, 1)\n",
    "            )\n",
    "            outs.append(col)\n",
    "        return np.hstack(outs)\n",
    "\n",
    "cat_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cert_ohe\",\n",
    "         OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"),\n",
    "         cat_low),\n",
    "        (\"people_freq\",\n",
    "         FrequencyEncoder(),\n",
    "         cat_high),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "X_cat = df[cat_low + cat_high].copy()\n",
    "X_cat_proc = cat_preprocessor.fit_transform(X_cat)\n",
    "\n",
    "# nomes das features resultantes\n",
    "ohe = cat_preprocessor.named_transformers_[\"cert_ohe\"]\n",
    "cert_names = list(ohe.get_feature_names_out(cat_low))  # ex.: ['Certificate_A', 'Certificate_R', ...]\n",
    "freq_names = [f\"freq_{c}\" for c in cat_high]\n",
    "\n",
    "cat_feature_names = cert_names + freq_names\n",
    "\n",
    "X_cat_proc_df = pd.DataFrame(X_cat_proc, columns=cat_feature_names, index=df.index)\n",
    "print(\"Shape após pré-processamento categórico:\", X_cat_proc_df.shape)\n",
    "X_cat_proc_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2daf5a02",
   "metadata": {},
   "source": [
    "Saída:\n",
    "- Colunas One-Hot para `Certificate` (ex.: `Certificate_A`, `Certificate_R`, …).\n",
    "- Uma coluna numérica por atributo de alta cardinalidade (ex.: `freq_Director`, `freq_Star1`, `freq_Star2`, `freq_Star3`).\n",
    "\n",
    "Observação:\n",
    "- Target Encoding é uma alternativa para alta cardinalidade, porém exige cuidado com vazamento de informação (deve ser feito com validação cruzada). Nesta etapa optamos por Frequency Encoding para manter simplicidade e robustez."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a971c5f9",
   "metadata": {},
   "source": [
    "#### 3.2.3.3 Transformações das variáveis de gênero\n",
    "\n",
    "Variáveis consideradas:\n",
    "- Colunas binárias: `Action`, `Adventure`, `Animation`, `Biography`, `Comedy`, `Crime`,\n",
    "  `Drama`, `Family`, `Fantasy`, `Film-Noir`, `History`, `Horror`, `Music`, `Musical`,\n",
    "  `Mystery`, `Romance`, `Sci-Fi`, `Sport`, `Thriller`, `War`, `Western`.\n",
    "\n",
    "Tratamento aplicado:\n",
    "- As colunas de gênero já estão em formato binário (0/1), portanto foram usadas **diretamente** no modelo via *passthrough* no `ColumnTransformer`.\n",
    "- A coluna textual `Genres_list` foi **descartada** por redundância.\n",
    "\n",
    "Observações:\n",
    "- Não é necessária normalização dessas colunas binárias.\n",
    "- Como os gêneros formam um conjunto multi-rótulo (um filme pode ter mais de um), não se aplica a remoção de uma categoria para evitar colinearidade típica de one-hot de uma única variável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ff7b3de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape após pré-processamento completo: (5129, 51)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>std_Released_Year</th>\n",
       "      <th>std_Runtime</th>\n",
       "      <th>log1p_std_Gross</th>\n",
       "      <th>log1p_std_budget</th>\n",
       "      <th>log1p_std_No_of_Votes</th>\n",
       "      <th>Certificate_16</th>\n",
       "      <th>Certificate_A</th>\n",
       "      <th>Certificate_Approved</th>\n",
       "      <th>Certificate_G</th>\n",
       "      <th>Certificate_GP</th>\n",
       "      <th>...</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Music</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.854601</td>\n",
       "      <td>2.864626</td>\n",
       "      <td>1.075159</td>\n",
       "      <td>-0.676131</td>\n",
       "      <td>2.209229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.488205</td>\n",
       "      <td>1.853034</td>\n",
       "      <td>1.723030</td>\n",
       "      <td>1.674331</td>\n",
       "      <td>2.410428</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.724445</td>\n",
       "      <td>4.052147</td>\n",
       "      <td>0.672068</td>\n",
       "      <td>-0.146074</td>\n",
       "      <td>2.002986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.830770</td>\n",
       "      <td>-0.609972</td>\n",
       "      <td>-0.539866</td>\n",
       "      <td>-2.624165</td>\n",
       "      <td>1.720658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.162815</td>\n",
       "      <td>4.008165</td>\n",
       "      <td>1.559523</td>\n",
       "      <td>1.210174</td>\n",
       "      <td>2.217081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   std_Released_Year  std_Runtime  log1p_std_Gross  log1p_std_budget  \\\n",
       "0          -1.854601     2.864626         1.075159         -0.676131   \n",
       "1           0.488205     1.853034         1.723030          1.674331   \n",
       "2          -1.724445     4.052147         0.672068         -0.146074   \n",
       "3          -2.830770    -0.609972        -0.539866         -2.624165   \n",
       "4           0.162815     4.008165         1.559523          1.210174   \n",
       "\n",
       "   log1p_std_No_of_Votes  Certificate_16  Certificate_A  Certificate_Approved  \\\n",
       "0               2.209229             0.0            1.0                   0.0   \n",
       "1               2.410428             0.0            0.0                   0.0   \n",
       "2               2.002986             0.0            1.0                   0.0   \n",
       "3               1.720658             0.0            0.0                   0.0   \n",
       "4               2.217081             0.0            0.0                   0.0   \n",
       "\n",
       "   Certificate_G  Certificate_GP  ...  Horror  Music  Musical  Mystery  \\\n",
       "0            0.0             0.0  ...     0.0    0.0      0.0      0.0   \n",
       "1            0.0             0.0  ...     0.0    0.0      0.0      0.0   \n",
       "2            0.0             0.0  ...     0.0    0.0      0.0      0.0   \n",
       "3            0.0             0.0  ...     0.0    0.0      0.0      0.0   \n",
       "4            0.0             0.0  ...     0.0    0.0      0.0      0.0   \n",
       "\n",
       "   Romance  Sci-Fi  Sport  Thriller  War  Western  \n",
       "0      0.0     0.0    0.0       0.0  0.0      0.0  \n",
       "1      0.0     0.0    0.0       0.0  0.0      0.0  \n",
       "2      0.0     0.0    0.0       0.0  0.0      0.0  \n",
       "3      0.0     0.0    0.0       0.0  0.0      0.0  \n",
       "4      0.0     0.0    0.0       0.0  0.0      0.0  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "num_linear = [\"Released_Year\", \"Runtime\"]\n",
    "num_skewed = [\"Gross\", \"budget\", \"No_of_Votes\"]\n",
    "cat_low  = [\"Certificate\"]                         \n",
    "cat_high = [\"Director\", \"Star1\", \"Star2\", \"Star3\"] \n",
    "\n",
    "\n",
    "genre_cols = [\n",
    "    \"Action\",\"Adventure\",\"Animation\",\"Biography\",\"Comedy\",\"Crime\",\"Drama\",\"Family\",\n",
    "    \"Fantasy\",\"Film-Noir\",\"History\",\"Horror\",\"Music\",\"Musical\",\"Mystery\",\"Romance\",\n",
    "    \"Sci-Fi\",\"Sport\",\"Thriller\",\"War\",\"Western\"\n",
    "]\n",
    "\n",
    "\n",
    "if \"Genres_list\" in df.columns:\n",
    "    df = df.drop(columns=[\"Genres_list\"])\n",
    "\n",
    "\n",
    "numeric_linear_pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "numeric_skewed_pipe = Pipeline([\n",
    "    (\"log1p\", FunctionTransformer(np.log1p, validate=False)),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "\n",
    "class FrequencyEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.maps_ = None\n",
    "        self.cols_ = None\n",
    "        self.n_ = None\n",
    "    def fit(self, X, y=None):\n",
    "        X = pd.DataFrame(X)\n",
    "        self.cols_ = list(X.columns)\n",
    "        self.n_ = len(X)\n",
    "        self.maps_ = {}\n",
    "        for i, c in enumerate(self.cols_):\n",
    "            vc = X.iloc[:, i].astype(str).value_counts(dropna=False)\n",
    "            self.maps_[c] = (vc / self.n_).to_dict()\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = pd.DataFrame(X)\n",
    "        outs = []\n",
    "        for i, c in enumerate(self.cols_):\n",
    "            m = self.maps_[c]\n",
    "            col = (\n",
    "                X.iloc[:, i].astype(str).map(m).fillna(0.0).to_numpy().reshape(-1, 1)\n",
    "            )\n",
    "            outs.append(col)\n",
    "        return np.hstack(outs)\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num_linear\",  numeric_linear_pipe,  num_linear),             # std\n",
    "        (\"num_skewed\",  numeric_skewed_pipe,  num_skewed),             # log1p + std\n",
    "        (\"cert_ohe\",    OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"),cat_low),   # OHE\n",
    "        (\"people_freq\", FrequencyEncoder(),   cat_high),                # frequência\n",
    "        (\"genres\",      \"passthrough\",        genre_cols),              # já binárias\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "\n",
    "X = df[num_linear + num_skewed + cat_low + cat_high + genre_cols].copy()\n",
    "X_proc = preprocessor.fit_transform(X)\n",
    "print(\"Shape após pré-processamento completo:\", X_proc.shape)\n",
    "\n",
    "num_feature_names = (\n",
    "    [f\"std_{c}\" for c in num_linear] +\n",
    "    [f\"log1p_std_{c}\" for c in num_skewed]\n",
    ")\n",
    "\n",
    "ohe = preprocessor.named_transformers_[\"cert_ohe\"]\n",
    "cert_names = list(ohe.get_feature_names_out(cat_low))\n",
    "\n",
    "freq_names = [f\"freq_{c}\" for c in cat_high]\n",
    "\n",
    "genre_names = genre_cols\n",
    "\n",
    "feature_names = num_feature_names + cert_names + freq_names + genre_names\n",
    "X_proc_df = pd.DataFrame(X_proc, columns=feature_names, index=df.index)\n",
    "X_proc_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7e2903",
   "metadata": {},
   "source": [
    "### 3.2.4 Conclusão de tratamento e seleção das variáveis\n",
    "\n",
    "**Numéricas**\n",
    "- `Released_Year`, `Runtime` → `StandardScaler`  \n",
    "  *Por quê:* coloca todas as variáveis na mesma escala (média 0, desvio 1), evitando que atributos com magnitude maior dominem modelos sensíveis à escala (p.ex., Regressão Linear).\n",
    "- `Gross`, `budget`, `No_of_Votes` → `log1p` + `StandardScaler`  \n",
    "  *Por quê:* `log1p` reduz assimetria e ordens de grandeza (variância mais estável e relações mais próximas de lineares); depois padronizamos para manter a comparabilidade entre atributos.\n",
    "\n",
    "**Categóricas**\n",
    "- `Certificate` → One-Hot Encoding  \n",
    "  *Por quê:* poucas categorias e sem ordem natural; OHE representa cada categoria sem impor ordenação artificial.\n",
    "- `Director`, `Star1`, `Star2`, `Star3` → Frequency Encoding  \n",
    "  *Por quê:* altíssima cardinalidade; evita explosão de colunas do OHE e ainda captura sinal de “popularidade/recorrência” das categorias. (Mais simples e robusto que Target Encoding, reduz risco de vazamento.)\n",
    "\n",
    "**Gêneros**\n",
    "- Colunas binárias (`Action` … `Western`) → *passthrough*  \n",
    "  *Por quê:* já estão em 0/1; não requerem codificação nem escala adicional.\n",
    "- `Genres_list` → removida  \n",
    "  *Por quê:* redundante com as colunas binárias e exigiria NLP para uso adequado.\n",
    "\n",
    "**Orquestração**\n",
    "- `ColumnTransformer` para unificar todas as etapas  \n",
    "  *Por quê:* garante o mesmo pré-processamento em treino/teste, melhora reprodutibilidade e evita vazamento acidental.\n",
    "- `df` original preservado; matriz final de features em `X_proc_df`  \n",
    "  *Por quê:* mantém rastreabilidade dos dados brutos e separa claramente *features* de *target*.\n",
    "\n",
    "**Saída do pré-processamento**\n",
    "- **Features transformadas:** `X = X_proc_df` com **5262 × 52** colunas.  \n",
    "- **Alvo (target):** `y = df[\"IMDB_Rating\"].values` com **5262** registros.\n",
    "\n",
    "**Próximo passo**\n",
    "- `train_test_split`, treinar baseline (Regressão Linear) e modelos de árvore/boosting (Random Forest, Gradient Boosting) e avaliar com **RMSE** e **MAE**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337ee520",
   "metadata": {},
   "source": [
    "## 3.3 Separação em treino e teste dos valores\n",
    "\n",
    "Para garantir uma avaliação justa da capacidade preditiva dos modelos, dividimos o conjunto de dados em duas partes: **80% para treino** e **20% para teste**.  \n",
    "\n",
    "- **Treino (X_train, y_train):** utilizado para ajustar os parâmetros internos dos modelos.  \n",
    "- **Teste (X_test, y_test):** mantido isolado durante o treino, serve para avaliar a performance em dados nunca vistos, simulando um cenário de generalização.  \n",
    "\n",
    "A proporção 80/20 foi escolhida por ser um padrão amplamente aceito: garante dados suficientes para aprendizado do modelo e, ao mesmo tempo, reserva uma amostra representativa para validação final.  \n",
    "O parâmetro `random_state=42` assegura **reprodutibilidade** da divisão, permitindo que os resultados sejam replicados.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "4911f3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho treino: 4103 amostras\n",
      "Tamanho teste : 1026 amostras\n"
     ]
    }
   ],
   "source": [
    "# ===== Divisão em treino e teste =====\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Features (X) já processadas\n",
    "X = X_proc_df\n",
    "\n",
    "# Target (y) = nota do IMDB\n",
    "y = df[\"IMDB_Rating\"].values\n",
    "\n",
    "# Separação 80% treino / 20% teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,      # 20% para teste\n",
    "    random_state=42,    # garante reprodutibilidade\n",
    "    shuffle=True        # embaralha antes da divisão\n",
    ")\n",
    "\n",
    "print(\"Tamanho treino:\", X_train.shape[0], \"amostras\")\n",
    "print(\"Tamanho teste :\", X_test.shape[0], \"amostras\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54884c1f",
   "metadata": {},
   "source": [
    "## 3.4 Avaliação dos modelos\n",
    "\n",
    "Para iniciar a etapa de modelagem, adotamos a **Regressão Linear** como modelo baseline.  \n",
    "A escolha se justifica por ser um algoritmo simples, rápido de treinar e de fácil interpretação, permitindo avaliar se as variáveis transformadas já carregam sinal preditivo suficiente.  \n",
    "Com esse baseline, poderemos comparar posteriormente com modelos mais complexos (Random Forest e XGBoost) e verificar ganhos reais de performance.\n",
    "\n",
    "### Métricas utilizadas\n",
    "Como o problema é de **regressão supervisionada**, utilizamos métricas que avaliam o erro entre as previsões e os valores reais:\n",
    "\n",
    "- **RMSE (Root Mean Squared Error):** métrica principal, pois penaliza mais fortemente erros grandes.  \n",
    "- **MAE (Mean Absolute Error):** complemento de fácil interpretação, indica o erro médio absoluto em pontos de nota IMDb.  \n",
    "- **R² (Coeficiente de Determinação):** mostra a proporção da variabilidade da nota explicada pelo modelo, útil como métrica adicional.\n",
    "\n",
    "Dessa forma, a análise será conduzida principalmente pelo **RMSE**, mas também observaremos **MAE** e **R²** para uma visão mais completa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71f7762",
   "metadata": {},
   "source": [
    "### 3.4.1 Regressão Linear\n",
    "- Modelo baseline: simples, rápido e interpretável.  \n",
    "- Serve como referência para verificar se modelos mais complexos trazem ganhos reais de performance.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "6a0b93c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Regressão Linear - Teste]\n",
      "MAE : 0.529\n",
      "RMSE: 0.730\n",
      "R²  : 0.594\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>erro_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.2</td>\n",
       "      <td>5.590744</td>\n",
       "      <td>0.609256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.5</td>\n",
       "      <td>6.335948</td>\n",
       "      <td>0.164052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2</td>\n",
       "      <td>6.754364</td>\n",
       "      <td>0.445636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.9</td>\n",
       "      <td>5.834197</td>\n",
       "      <td>0.065803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.8</td>\n",
       "      <td>6.356622</td>\n",
       "      <td>0.443378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y_true    y_pred  erro_abs\n",
       "0     6.2  5.590744  0.609256\n",
       "1     6.5  6.335948  0.164052\n",
       "2     7.2  6.754364  0.445636\n",
       "3     5.9  5.834197  0.065803\n",
       "4     6.8  6.356622  0.443378"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# ===== 2) Instanciar e treinar o modelo =====\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "\n",
    "# ===== 3) Predições =====\n",
    "y_pred = linreg.predict(X_test)\n",
    "\n",
    "# ===== 4) Avaliação =====\n",
    "mae  = mean_absolute_error(y_test, y_pred)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "r2   = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"[Regressão Linear - Teste]\")\n",
    "print(f\"MAE : {mae:.3f}\")\n",
    "print(f\"RMSE: {rmse:.3f}\")\n",
    "print(f\"R²  : {r2:.3f}\")\n",
    "\n",
    "# ===== 5) (Opcional) Guardar resultados para análise posterior =====\n",
    "resultados_baseline = pd.DataFrame({\n",
    "    \"y_true\": y_test,\n",
    "    \"y_pred\": y_pred,\n",
    "    \"erro_abs\": np.abs(y_test - y_pred)\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "resultados_baseline.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1af52a1",
   "metadata": {},
   "source": [
    "#### Resultados da Regressão Linear\n",
    "\n",
    "O modelo de **Regressão Linear** foi utilizado como baseline, servindo como ponto de partida para comparação com modelos mais complexos.\n",
    "\n",
    "**Métricas obtidas no conjunto de teste:**\n",
    "- **MAE (Mean Absolute Error):** 0.520  \n",
    "  → Em média, o modelo erra cerca de **0,52 pontos** na nota IMDb (em uma escala de 0 a 10).  \n",
    "\n",
    "- **RMSE (Root Mean Squared Error):** 0.730  \n",
    "  → Erros maiores são penalizados mais fortemente; neste caso, o erro típico é de aproximadamente **0,73 pontos**.  \n",
    "\n",
    "- **R² (Coeficiente de Determinação):** 0.594  \n",
    "  → O modelo consegue explicar cerca de **59% da variabilidade** da nota IMDb a partir das variáveis disponíveis.  \n",
    "\n",
    "**Análise:**  \n",
    "- Os resultados mostram que a regressão linear já captura uma parte relevante da relação entre as variáveis e a nota do IMDb, mas ainda deixa **~40% da variabilidade sem explicação**.  \n",
    "- O MAE e RMSE estão em níveis aceitáveis, mas sugerem espaço para melhoria, especialmente em casos onde a nota real é mais extrema (erros maiores penalizam o RMSE).  \n",
    "- Isso confirma a **importância de testar modelos mais complexos** (como Random Forest e Gradient Boosting), que podem capturar relações não-lineares e interações entre variáveis que a regressão linear não consegue modelar.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6ba2c5",
   "metadata": {},
   "source": [
    "### 3.4.2 Random Forest Regressor\n",
    "\n",
    "- Modelo baseado em um conjunto de árvores de decisão, construídas sobre subconjuntos de dados e variáveis.  \n",
    "- Captura **relações não lineares** e **interações entre atributos**, sem exigir normalização das variáveis.  \n",
    "- É mais robusto a outliers e tende a reduzir o risco de overfitting em comparação a uma única árvore de decisão.  \n",
    "- Serve como próximo passo após o baseline para verificar ganhos de performance com um modelo mais complexo.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c249cd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Random Forest - Teste]\n",
      "MAE : 0.463\n",
      "RMSE: 0.664\n",
      "R²  : 0.663\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "log1p_std_No_of_Votes    0.328738\n",
       "Drama                    0.116148\n",
       "log1p_std_budget         0.106153\n",
       "std_Released_Year        0.100520\n",
       "std_Runtime              0.080315\n",
       "log1p_std_Gross          0.063631\n",
       "freq_Star1               0.026460\n",
       "Certificate_PG-13        0.021130\n",
       "freq_Director            0.018715\n",
       "freq_Star2               0.016872\n",
       "Thriller                 0.011600\n",
       "freq_Star3               0.011337\n",
       "Horror                   0.010230\n",
       "Animation                0.008685\n",
       "Certificate_R            0.007720\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Garantia: usar os mesmos splits\n",
    "assert 'X_train' in globals() and 'X_test' in globals(), \"Faça a divisão treino/teste antes.\"\n",
    "assert 'y_train' in globals() and 'y_test' in globals(), \"Faça a divisão treino/teste antes.\"\n",
    "\n",
    "# 1) Instanciar o modelo (setup inicial e reprodutível)\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=300,      # número de árvores\n",
    "    max_depth=None,        # deixe crescer; ajustaremos depois se precisar\n",
    "    min_samples_leaf=1,    # padrão\n",
    "    n_jobs=-1,             # usa todos os núcleos\n",
    "    random_state=42,       # reprodutibilidade\n",
    ")\n",
    "# 2) Treinar\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# 3) Predizer\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# 4) Avaliar (RMSE calculado como raiz do MSE para compatibilidade entre versões)\n",
    "mae_rf  = mean_absolute_error(y_test, y_pred_rf)\n",
    "mse_rf  = mean_squared_error(y_test, y_pred_rf)\n",
    "rmse_rf = np.sqrt(mse_rf)\n",
    "r2_rf   = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"[Random Forest - Teste]\")\n",
    "print(f\"MAE : {mae_rf:.3f}\")\n",
    "print(f\"RMSE: {rmse_rf:.3f}\")\n",
    "print(f\"R²  : {r2_rf:.3f}\")\n",
    "\n",
    "# 5) (Opcional) Tabela de resultados para comparar depois\n",
    "resultados_rf = pd.DataFrame({\n",
    "    \"y_true\": y_test,\n",
    "    \"y_pred\": y_pred_rf,\n",
    "    \"erro_abs\": np.abs(y_test - y_pred_rf)\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "# 6) (Opcional) Importâncias de variáveis (top 15) — útil para diagnóstico\n",
    "try:\n",
    "    importances = pd.Series(rf.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "    display(importances.head(15))\n",
    "except Exception as e:\n",
    "    print(\"Não foi possível calcular importâncias:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192035cd",
   "metadata": {},
   "source": [
    "#### Resultados do Random Forest Regressor\n",
    "\n",
    "**Métricas obtidas no conjunto de teste:**\n",
    "- **MAE (Mean Absolute Error):** 0.463  \n",
    "  → O erro médio absoluto caiu em relação à regressão linear (0.520 → 0.463), ou seja, o modelo erra menos em média.  \n",
    "\n",
    "- **RMSE (Root Mean Squared Error):** 0.664  \n",
    "  → O erro típico (com maior penalização para erros grandes) também melhorou em relação ao baseline (0.730 → 0.664).  \n",
    "\n",
    "- **R² (Coeficiente de Determinação):** 0.663  \n",
    "  → O modelo explica **66% da variabilidade** da nota IMDb, contra 59% da regressão linear.  \n",
    "\n",
    "**Análise:**  \n",
    "- O **Random Forest superou a Regressão Linear** em todas as métricas, mostrando que capturar relações não lineares e interações entre variáveis melhora a qualidade das previsões.  \n",
    "- O ganho em R² (de 0.594 → 0.663) indica que o modelo consegue explicar uma fatia maior da variação nas notas.  \n",
    "- As importâncias de variáveis apontam que o número de votos (`log1p_std_No_of_Votes`), gênero *Drama* e orçamento (`log1p_std_budget`) são fatores muito relevantes para prever a nota.  \n",
    "- Apesar da melhora, ainda existe cerca de 34% da variabilidade não explicada, reforçando que outros algoritmos (como Gradient Boosting) podem trazer ganhos adicionais.  \n",
    "\n",
    "**Conclusão parcial:**  \n",
    "O Random Forest demonstrou ser um avanço claro sobre o baseline. Na próxima etapa, testaremos o **Gradient Boosting (XGBoost/LightGBM)** para verificar se conseguimos reduzir ainda mais o erro e aumentar o poder explicativo do modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e4f41f",
   "metadata": {},
   "source": [
    "### 3.4.3 XGBoost\n",
    "\n",
    "- Algoritmo de **boosting de árvores**, onde cada árvore é treinada sequencialmente para corrigir os erros das anteriores.  \n",
    "- Considerado um dos modelos mais eficientes para dados tabulares, geralmente superando Random Forest em performance.  \n",
    "- Captura **relações não lineares** e **interações entre variáveis**, com regularização para evitar overfitting.  \n",
    "- Serve como próximo passo após o Random Forest para verificar se o ajuste sequencial reduz o erro e melhora o poder explicativo do modelo.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "211241c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[XGBoost - Teste]\n",
      "MAE : 0.449\n",
      "RMSE: 0.644\n",
      "R²  : 0.684\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Drama                    0.141517\n",
       "Certificate_U            0.101224\n",
       "Animation                0.054244\n",
       "Certificate_PG-13        0.052296\n",
       "log1p_std_No_of_Votes    0.050663\n",
       "Horror                   0.033309\n",
       "Thriller                 0.026087\n",
       "Certificate_UA           0.025682\n",
       "Certificate_PG           0.025466\n",
       "log1p_std_budget         0.025065\n",
       "Certificate_R            0.024547\n",
       "Biography                0.022713\n",
       "Musical                  0.022631\n",
       "std_Runtime              0.022464\n",
       "Certificate_X            0.022309\n",
       "dtype: float32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "assert 'X_train' in globals() and 'X_test' in globals(), \"Faça a divisão treino/teste antes.\"\n",
    "assert 'y_train' in globals() and 'y_test' in globals(), \"Faça a divisão treino/teste antes.\"\n",
    "\n",
    "# 1) Instanciar o modelo\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.85,\n",
    "    colsample_bytree=0.85,\n",
    "    reg_lambda=1.0,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    tree_method=\"hist\",   # rápido e estável\n",
    "    objective=\"reg:squarederror\",\n",
    "    verbosity=0,\n",
    ")\n",
    "\n",
    "# 2) Treinar\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# 3) Predizer\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# 4) Avaliar\n",
    "mae_xgb  = mean_absolute_error(y_test, y_pred_xgb)\n",
    "mse_xgb  = mean_squared_error(y_test, y_pred_xgb)\n",
    "rmse_xgb = np.sqrt(mse_xgb)\n",
    "r2_xgb   = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(\"[XGBoost - Teste]\")\n",
    "print(f\"MAE : {mae_xgb:.3f}\")\n",
    "print(f\"RMSE: {rmse_xgb:.3f}\")\n",
    "print(f\"R²  : {r2_xgb:.3f}\")\n",
    "\n",
    "# 5) (Opcional) Importâncias de features\n",
    "importances_xgb = pd.Series(xgb_model.feature_importances_, index=X_train.columns)\\\n",
    "                    .sort_values(ascending=False).head(15)\n",
    "display(importances_xgb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30a386a",
   "metadata": {},
   "source": [
    "#### Resultados do XGBoost\n",
    "\n",
    "**Métricas obtidas no conjunto de teste:**\n",
    "- **MAE (Mean Absolute Error):** 0.449  \n",
    "  → O menor erro médio até agora, indicando previsões mais próximas das notas reais.  \n",
    "\n",
    "- **RMSE (Root Mean Squared Error):** 0.644  \n",
    "  → Redução em relação ao Random Forest (0.664) e à Regressão Linear (0.730), com menor penalização de erros grandes.  \n",
    "\n",
    "- **R² (Coeficiente de Determinação):** 0.684  \n",
    "  → O modelo explica cerca de **68% da variabilidade** da nota IMDb, superando o Random Forest (66%) e a Regressão Linear (59%).  \n",
    "\n",
    "**Análise:**  \n",
    "- O XGBoost apresentou **ganho consistente em todas as métricas** comparado aos modelos anteriores.  \n",
    "- Mostrou maior capacidade de capturar padrões complexos, reduzindo o erro médio e aumentando o R².  \n",
    "- As importâncias de variáveis reforçam que `No_of_Votes`, `Drama` e `budget` continuam como fatores centrais para previsão.  \n",
    "- Apesar da melhora, ainda existe cerca de 32% da variabilidade não explicada, o que indica limites impostos pelos dados disponíveis.  \n",
    "\n",
    "**Conclusão parcial:**  \n",
    "O XGBoost superou a Regressão Linear e o Random Forest, consolidando-se como o melhor modelo até o momento. Na próxima etapa, testaremos o **CatBoost**, que pode explorar variáveis categóricas de maneira ainda mais eficiente e potencialmente trazer ganhos adicionais."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d2c795",
   "metadata": {},
   "source": [
    "### 3.4.4 HistGradientBoosting (sklearn)\n",
    "\n",
    "- Variante de Gradient Boosting integrada ao scikit-learn, otimizada via histogramas para acelerar os cálculos.  \n",
    "- Captura **relações não lineares** e **interações entre variáveis** de forma semelhante ao XGBoost, mas com implementação mais leve.  \n",
    "- Serve como alternativa ao XGBoost em cenários onde se busca simplicidade e integração com o ecossistema sklearn.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d3114b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HistGradientBoosting - Teste]\n",
      "MAE : 0.457\n",
      "RMSE: 0.650\n",
      "R²  : 0.678\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "log1p_std_No_of_Votes    0.814464\n",
       "Drama                    0.094613\n",
       "std_Released_Year        0.093470\n",
       "log1p_std_budget         0.085592\n",
       "log1p_std_Gross          0.059928\n",
       "std_Runtime              0.052958\n",
       "Animation                0.031573\n",
       "Horror                   0.014636\n",
       "Certificate_PG-13        0.011784\n",
       "Thriller                 0.011071\n",
       "Action                   0.010079\n",
       "freq_Star1               0.007644\n",
       "freq_Director            0.005704\n",
       "Certificate_R            0.005530\n",
       "Comedy                   0.004615\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Garantia: usar o mesmo split\n",
    "assert 'X_train' in globals() and 'X_test' in globals(), \"Faça a divisão treino/teste antes.\"\n",
    "assert 'y_train' in globals() and 'y_test' in globals(), \"Faça a divisão treino/teste antes.\"\n",
    "\n",
    "# 1) Instanciar o modelo\n",
    "hgb_model = HistGradientBoostingRegressor(\n",
    "    learning_rate=0.06,\n",
    "    max_depth=None,\n",
    "    max_iter=300,\n",
    "    l2_regularization=0.0,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# 2) Treinar\n",
    "hgb_model.fit(X_train, y_train)\n",
    "\n",
    "# 3) Predizer\n",
    "y_pred_hgb = hgb_model.predict(X_test)\n",
    "\n",
    "# 4) Avaliar\n",
    "mae_hgb  = mean_absolute_error(y_test, y_pred_hgb)\n",
    "mse_hgb  = mean_squared_error(y_test, y_pred_hgb)\n",
    "rmse_hgb = np.sqrt(mse_hgb)\n",
    "r2_hgb   = r2_score(y_test, y_pred_hgb)\n",
    "\n",
    "print(\"[HistGradientBoosting - Teste]\")\n",
    "print(f\"MAE : {mae_hgb:.3f}\")\n",
    "print(f\"RMSE: {rmse_hgb:.3f}\")\n",
    "print(f\"R²  : {r2_hgb:.3f}\")\n",
    "\n",
    "# Importâncias via permutação (pode ser mais lento)\n",
    "result = permutation_importance(\n",
    "    hgb_model, X_test, y_test, \n",
    "    n_repeats=10, random_state=42, n_jobs=-1\n",
    ")\n",
    "\n",
    "importances_hgb = pd.Series(result.importances_mean, index=X_train.columns)\\\n",
    "                    .sort_values(ascending=False).head(15)\n",
    "\n",
    "display(importances_hgb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc55cb5",
   "metadata": {},
   "source": [
    "#### Resultados do HistGradientBoosting\n",
    "\n",
    "**Métricas obtidas no conjunto de teste:**\n",
    "- **MAE (Mean Absolute Error):** 0.457  \n",
    "  → Um erro médio comparável ao XGBoost (0.449), mas ainda ligeiramente superior.  \n",
    "\n",
    "- **RMSE (Root Mean Squared Error):** 0.650  \n",
    "  → Valor próximo ao XGBoost (0.644), mostrando boa capacidade de generalização.  \n",
    "\n",
    "- **R² (Coeficiente de Determinação):** 0.678  \n",
    "  → Explica cerca de **68% da variabilidade** das notas IMDb, em linha com o XGBoost, mas com resultado marginalmente inferior.  \n",
    "\n",
    "**Análise:**  \n",
    "- O HistGradientBoosting entregou resultados sólidos, superiores ao Random Forest e à Regressão Linear.  \n",
    "- Apesar de não superar o XGBoost, mostrou ser uma **opção competitiva e mais integrada ao sklearn**.  \n",
    "- A proximidade nos resultados evidencia que o ganho entre variantes de boosting é incremental, e não disruptivo.  \n",
    "\n",
    "**Conclusão parcial:**  \n",
    "O HistGradientBoosting confirmou o padrão de bom desempenho dos modelos de boosting, ficando muito próximo ao XGBoost, mas sem superá-lo. O próximo passo será testar o **CatBoost**, que pode oferecer ganhos adicionais ao lidar de forma diferenciada com variáveis categóricas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8171e59f",
   "metadata": {},
   "source": [
    "### 3.4.5 CatBoost\n",
    "\n",
    "- Algoritmo de **gradient boosting** desenvolvido para lidar de forma mais eficiente com variáveis categóricas.  \n",
    "- Possui mecanismos internos que reduzem a necessidade de pré-processamento pesado, evitando overfitting e acelerando o treinamento.  \n",
    "- Foi testado aqui como o último modelo, após a Regressão Linear, Random Forest e outras variantes de boosting, para verificar ganhos adicionais.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "cb616311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CatBoost - Teste]\n",
      "MAE : 0.444\n",
      "RMSE: 0.643\n",
      "R²  : 0.685\n"
     ]
    }
   ],
   "source": [
    "# Garantia: usar o mesmo split\n",
    "assert 'X_train' in globals() and 'X_test' in globals(), \"Faça a divisão treino/teste antes.\"\n",
    "assert 'y_train' in globals() and 'y_test' in globals(), \"Faça a divisão treino/teste antes.\"\n",
    "\n",
    "try:\n",
    "    from catboost import CatBoostRegressor\n",
    "\n",
    "    # 1) Instanciar o modelo\n",
    "    cat = CatBoostRegressor(\n",
    "        iterations=500,\n",
    "        learning_rate=0.05,\n",
    "        depth=8,\n",
    "        random_seed=42,\n",
    "        verbose=0,\n",
    "        allow_writing_files=False,  # <- não cria catboost_info\n",
    "    )\n",
    "\n",
    "    # 2) Treinar\n",
    "    cat.fit(X_train, y_train)\n",
    "\n",
    "    # 3) Predizer\n",
    "    y_pred_cat = cat.predict(X_test)\n",
    "\n",
    "    # 4) Avaliar\n",
    "    mae_cat  = mean_absolute_error(y_test, y_pred_cat)\n",
    "    mse_cat  = mean_squared_error(y_test, y_pred_cat)\n",
    "    rmse_cat = np.sqrt(mse_cat)\n",
    "    r2_cat   = r2_score(y_test, y_pred_cat)\n",
    "\n",
    "    print(\"[CatBoost - Teste]\")\n",
    "    print(f\"MAE : {mae_cat:.3f}\")\n",
    "    print(f\"RMSE: {rmse_cat:.3f}\")\n",
    "    print(f\"R²  : {r2_cat:.3f}\")\n",
    "\n",
    "    # 5) (Opcional) DataFrame de resultados\n",
    "    resultados_cat = pd.DataFrame({\n",
    "        \"y_true\": y_test,\n",
    "        \"y_pred\": y_pred_cat,\n",
    "        \"erro_abs\": np.abs(y_test - y_pred_cat)\n",
    "    }).reset_index(drop=True)\n",
    "\n",
    "except ImportError:\n",
    "    print(\"CatBoost não está instalado. Rode: pip install catboost\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d5b9f2",
   "metadata": {},
   "source": [
    "\n",
    "#### Resultados do CatBoost\n",
    "\n",
    "**Métricas obtidas no conjunto de teste:**\n",
    "- **MAE (Mean Absolute Error):** 0.444  \n",
    "  → O menor erro médio entre todos os modelos, mostrando previsões bastante próximas das notas reais.  \n",
    "\n",
    "- **RMSE (Root Mean Squared Error):** 0.643  \n",
    "  → Também o menor RMSE até agora, indicando que o CatBoost lida melhor com erros maiores.  \n",
    "\n",
    "- **R² (Coeficiente de Determinação):** 0.685  \n",
    "  → Explica cerca de **68,5% da variabilidade** das notas IMDb, o maior valor entre os modelos testados.  \n",
    "\n",
    "**Análise:**  \n",
    "- O CatBoost apresentou a **melhor performance geral**, superando Regressão Linear, Random Forest e até mesmo o XGBoost.  \n",
    "- A redução do MAE e RMSE, ainda que marginal em relação ao XGBoost, confirma sua capacidade de capturar relações complexas.  \n",
    "- O ganho adicional provavelmente se deve ao tratamento interno mais sofisticado de variáveis categóricas, mesmo após nossas transformações prévias.  \n",
    "- Ainda assim, existe aproximadamente 31,5% da variabilidade que não foi explicada — evidenciando limites dos dados disponíveis.  \n",
    "\n",
    "**Conclusão parcial:**  \n",
    "O **CatBoost** foi o modelo vencedor neste estudo, atingindo o melhor equilíbrio entre erro médio e capacidade explicativa. Ele se consolida como a escolha final para previsão das notas IMDb neste conjunto de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552c0fc6",
   "metadata": {},
   "source": [
    "### 3.4.6 Comparação dos Modelos\n",
    "\n",
    "| Modelo                | MAE   | RMSE  | R²    |\n",
    "|------------------------|-------|-------|-------|\n",
    "| Regressão Linear       | 0.520 | 0.730 | 0.594 |\n",
    "| Random Forest          | 0.463 | 0.664 | 0.663 |\n",
    "| HistGradientBoosting   | 0.457 | 0.650 | 0.678 |\n",
    "| XGBoost                | 0.449 | 0.644 | 0.684 |\n",
    "| **CatBoost**           | **0.444** | **0.643** | **0.685** |\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusões finais\n",
    "\n",
    "- A **Regressão Linear** cumpriu seu papel como baseline, mas explicou apenas ~59% da variabilidade das notas IMDb.  \n",
    "- O **Random Forest** trouxe um avanço claro, capturando relações não lineares e elevando o R² para ~66%.  \n",
    "- Os modelos de **boosting** mostraram melhor desempenho: tanto o **HistGradientBoosting** quanto o **XGBoost** aumentaram a capacidade explicativa para ~68%, reduzindo consistentemente os erros.  \n",
    "- O **CatBoost** apresentou o **melhor resultado geral**, com menor MAE e RMSE e o maior R² (≈ 0.685).  \n",
    "---\n",
    "### Conclusão geral\n",
    "\n",
    "Entre todos os modelos testados, o **CatBoost** se mostrou o que melhor se aproxima dos dados, apresentando o menor erro (MAE = 0.444, RMSE = 0.643) e o maior poder explicativo (R² = 0.685).  \n",
    "Seus principais **prós** são: lidar de forma eficiente com variáveis categóricas, robustez contra overfitting e excelente desempenho em dados tabulares. Como **contra**, pode exigir mais tempo de treino em comparação a modelos mais simples e apresenta menor interpretabilidade em relação à Regressão Linear.  \n",
    "\n",
    "Para avaliar os modelos, utilizamos as métricas **MAE, RMSE e R²**, pois tratamos de um problema de **regressão supervisionada** (a variável alvo é contínua).  \n",
    "- O **MAE** indica o erro médio absoluto em pontos da nota IMDb, de fácil interpretação.  \n",
    "- O **RMSE** foi escolhido como **métrica principal**, pois penaliza mais fortemente erros grandes, que são mais críticos neste contexto.  \n",
    "- O **R²** complementa a análise, mostrando a proporção da variabilidade da nota que o modelo consegue explicar.  \n",
    "\n",
    "Dessa forma, concluímos que o **CatBoost** é o modelo mais adequado para este problema, alcançando o melhor equilíbrio entre erro médio e capacidade explicativa.  \n",
    "Ainda assim, aproximadamente 31,5% da variabilidade permanece não explicada, o que indica que fatores externos ao dataset (como recepção crítica especializada, contexto cultural ou marketing) também influenciam significativamente as notas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3efe31",
   "metadata": {},
   "source": [
    "# 4. Previsão da nota do IMDb para um novo filme\n",
    "\n",
    "Aplicamos o **mesmo pré-processamento** utilizado no treino (log1p + StandardScaler para variáveis assimétricas, StandardScaler para numéricas lineares, One-Hot em `Certificate`, Frequency Encoding em `Director`/`Stars` e gêneros binários em *passthrough*) ao registro do filme fornecido. Em seguida, usamos o **modelo final (CatBoost)** para obter a previsão.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6b5e51",
   "metadata": {},
   "source": [
    "## 4.1 Preparação dos dados: \n",
    "\n",
    "\n",
    "1. Conversão de tipos:\n",
    "   - `Runtime` → inteiro (minutos)  \n",
    "   - `Gross` → numérico (remoção de `,`)  \n",
    "   - `Released_Year` → numérico\n",
    "2. Preenchimento de variáveis ausentes:\n",
    "   - `budget` (não fornecido) → **mediana** do conjunto de treino.\n",
    "3. Gêneros:\n",
    "   - Criação das colunas binárias (`Action`, `Drama`, …, `Western`) a partir de `Genre`.\n",
    "4. Alinhamento com o dataset de treino:\n",
    "   - Inclusão de `IMDB_Rating` como `NaN` (alvo, não usado na predição).  \n",
    "   - `reindex` para garantir **as mesmas 35 colunas e dtypes** do treino.\n",
    "\n",
    "> Resultado: `df_novo` fica 100% compatível com o pipeline de treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "1b41564f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionário do filme fornecido\n",
    "novo_filme = {\n",
    "    'Series_Title': 'The Shawshank Redemption',\n",
    "    'Released_Year': '1994',\n",
    "    'Certificate': 'A',\n",
    "    'Runtime': '142 min',\n",
    "    'Genre': 'Drama',\n",
    "    'Overview': 'Two imprisoned men bond over a number of years, finding solace and eventual redemption through acts of common decency.',\n",
    "    'Meta_score': 80.0,\n",
    "    'Director': 'Frank Darabont',\n",
    "    'Star1': 'Tim Robbins',\n",
    "    'Star2': 'Morgan Freeman',\n",
    "    'Star3': 'Bob Gunton',\n",
    "    'Star4': 'William Sadler',\n",
    "    'No_of_Votes': 2343110,\n",
    "    'Gross': '28,341,469'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "a8525701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar DataFrame a partir do dicionário fornecido\n",
    "df_novo = pd.DataFrame([novo_filme])\n",
    "\n",
    "# Preencher variáveis ausentes com valores default (mediana do dataset)\n",
    "df_novo[\"budget\"] = df[\"budget\"].median()\n",
    "\n",
    "# Ajustar colunas de formato\n",
    "df_novo[\"Runtime\"] = df_novo[\"Runtime\"].str.replace(\" min\", \"\").astype(int)\n",
    "df_novo[\"Gross\"] = df_novo[\"Gross\"].str.replace(\",\", \"\").astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "2c4320f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar DataFrame do novo filme\n",
    "df_novo = pd.DataFrame([novo_filme])\n",
    "\n",
    "# Ajustar colunas numéricas\n",
    "df_novo[\"Runtime\"] = df_novo[\"Runtime\"].str.replace(\" min\", \"\").astype(float)\n",
    "df_novo[\"Gross\"] = df_novo[\"Gross\"].str.replace(\",\", \"\").astype(float)\n",
    "df_novo[\"Released_Year\"] = df_novo[\"Released_Year\"].astype(float)\n",
    "\n",
    "# Preencher variáveis ausentes\n",
    "df_novo[\"budget\"] = df[\"budget\"].median()\n",
    "if \"Meta_score\" not in df_novo or pd.isna(df_novo[\"Meta_score\"].iloc[0]):\n",
    "    df_novo[\"Meta_score\"] = df[\"Meta_score\"].median()\n",
    "\n",
    "# Criar colunas de gêneros (Action, Adventure, ..., Western)\n",
    "generos = ['Action','Adventure','Animation','Biography','Comedy','Crime','Drama','Family','Fantasy',\n",
    "           'Film-Noir','History','Horror','Music','Musical','Mystery','Romance','Sci-Fi',\n",
    "           'Sport','Thriller','War','Western']\n",
    "\n",
    "# Inicializar com 0\n",
    "for g in generos:\n",
    "    df_novo[g] = 0\n",
    "\n",
    "# Marcar os gêneros do filme\n",
    "for g in generos:\n",
    "    if g in df_novo.loc[0, \"Genre\"]:\n",
    "        df_novo.loc[0, g] = 1\n",
    "\n",
    "# Adicionar a coluna IMDB_Rating vazia (para alinhar)\n",
    "df_novo[\"IMDB_Rating\"] = np.nan\n",
    "\n",
    "# Reindexar para alinhar com df original\n",
    "df_novo = df_novo.reindex(columns=df.columns, fill_value=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a056da",
   "metadata": {},
   "source": [
    "## 4.2 Aplicando o Modelo: \n",
    "\n",
    "- Usamos as **mesmas features** do treino:  \n",
    "  `num_linear + num_skewed + cat_low + cat_high + genre_cols`.\n",
    "- **Sem refitar** o pré-processador: apenas `preprocessor.transform(df_novo[feature_cols])`.\n",
    "- Predição com o **CatBoost** treinado.\n",
    "\n",
    "**Nota prevista (CatBoost): 8.93**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "dc1354dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nota prevista para o IMDb: 8.93\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_cols = num_linear + num_skewed + cat_low + cat_high + genre_cols\n",
    "\n",
    "\n",
    "X_novo = preprocessor.transform(df_novo[feature_cols])\n",
    "\n",
    "\n",
    "pred_nota = cat.predict(X_novo)\n",
    "\n",
    "print(\"Nota prevista para o IMDb:\", round(float(pred_nota[0]), 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d59db8",
   "metadata": {},
   "source": [
    "## 4.3 Comparação com a nota oficial do IMDb\n",
    "\n",
    "- **Nota prevista:** 8.93  \n",
    "- **Nota real (IMDb):** 9.30\n",
    "\n",
    "**Erro absoluto:** |9.30 − 8.93| = **0.37** ponto  \n",
    "**Erro percentual:** **≈ 3,98%**\n",
    "\n",
    "**Leitura:** o erro desta previsão é **menor que o MAE do modelo** (≈ 0.44) e abaixo do **RMSE** (≈ 0.64), indicando que a estimativa está **dentro do esperado** para a performance do CatBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e304940e",
   "metadata": {},
   "source": [
    "# 5. Salvando o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc38776",
   "metadata": {},
   "source": [
    "Para reaproveitar o que foi treinado, vamos salvar **todo o pipeline**:\n",
    "- `preprocessor` (**ColumnTransformer** já *fitado*), que contém *log1p*, *StandardScaler*, *One-Hot*, *Frequency Encoding* e *passthrough* de gêneros;\n",
    "- `model` (o **CatBoost** já treinado);\n",
    "- `feature_cols` (lista de colunas brutas esperadas);\n",
    "- `metadata` (versões do ambiente, útil para reprodutibilidade).\n",
    "\n",
    "> Vantagem: ao carregar o `.pkl`, basta aplicar `preprocessor.transform()` e chamar `model.predict()` — sem refazer nenhuma transformação manual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "81cfec82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Modelo salvo em: C:\\Users\\guima\\Desktop\\Desafio_Guilherme\\models\\imdb_catboost_pipeline.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models_dir = (Path.cwd() / \"..\" / \"models\").resolve()\n",
    "if not models_dir.exists():\n",
    "    # fallback: se o CWD já for a raiz do projeto\n",
    "    models_dir = (Path.cwd() / \"models\").resolve()\n",
    "\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "artifact = {\n",
    "    \"preprocessor\": preprocessor,  # ColumnTransformer já fitado\n",
    "    \"model\": cat,                  # CatBoost já treinado\n",
    "    \"feature_cols\": num_linear + num_skewed + cat_low + cat_high + genre_cols,\n",
    "    \"metadata\": {\n",
    "        \"python\": sys.version,\n",
    "        \"sklearn\": sklearn.__version__,\n",
    "    }\n",
    "}\n",
    "\n",
    "# 3) Salvar\n",
    "pkl_path = models_dir / \"imdb_catboost_pipeline.pkl\"\n",
    "joblib.dump(artifact, pkl_path)\n",
    "print(f\" Modelo salvo em: {pkl_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11070e3b",
   "metadata": {},
   "source": [
    "Carregando o modelo: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "e39b5357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pipeline carregado com sucesso.\n"
     ]
    }
   ],
   "source": [
    "# Localiza o arquivo (fora de notebooks/ ou no diretório atual)\n",
    "pkl_path = (Path.cwd() / \"..\" / \"models\" / \"imdb_catboost_pipeline.pkl\").resolve()\n",
    "if not pkl_path.exists():\n",
    "    pkl_path = (Path.cwd() / \"models\" / \"imdb_catboost_pipeline.pkl\").resolve()\n",
    "\n",
    "art = joblib.load(pkl_path)\n",
    "\n",
    "preprocessor = art[\"preprocessor\"]\n",
    "model        = art[\"model\"]\n",
    "feature_cols = art[\"feature_cols\"]\n",
    "\n",
    "print(\" Pipeline carregado com sucesso.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0b2aa9",
   "metadata": {},
   "source": [
    "Tetando novamente!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "d418df9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nota prevista para o IMDb: 8.93\n"
     ]
    }
   ],
   "source": [
    "X_novo = preprocessor.transform(df_novo[feature_cols])\n",
    "pred   = model.predict(X_novo)\n",
    "\n",
    "print(\"Nota prevista para o IMDb:\", round(float(pred[0]), 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
